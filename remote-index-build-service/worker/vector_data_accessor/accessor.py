from dataclasses import dataclass

import numpy as np
from models.data_model import CreateIndexRequest
import s3.s3client as s3


@dataclass
class VectorsDataset:
    vectors: np.ndarray
    ids: np.array
    dimensions: int

    @staticmethod
    def get_vector_dataset(createIndexRequest: CreateIndexRequest):
        if not s3.check_s3_object_exists(createIndexRequest.bucketName, createIndexRequest.objectLocation):
            raise TypeError(f"{createIndexRequest.objectLocation} does not exist in the bucket : {createIndexRequest.bucketName}")
        vector_file = s3.download_s3_file_in_chunks(createIndexRequest.bucketName, createIndexRequest.objectLocation)
        return VectorsDataset.__parse(vector_file, createIndexRequest.dimensions, createIndexRequest.numberOfVectors)

    @staticmethod
    def __parse(vector_file: str, dimension: int, number_of_vectors: int,
            id_dtype: str = '<i8', vector_dtype: str = '<f4'):
        """
        Parse binary vector data from a file into a VectorsDataset object.

        This private static method reads binary data containing vectors and their IDs
        from a file. The data is expected to be in little-endian format, typically
        written by Java applications.

        Args:
            vector_file (str): Path to the binary file containing vector data.
            dimension (int): Number of dimensions for each vector.
            number_of_vectors (int): Total number of vectors to read from the file.
            id_dtype (str, optional): NumPy dtype for reading IDs.
                Defaults to '<i8' (little-endian 64-bit integer).
            vector_dtype (str, optional): NumPy dtype for reading vector values.
                Defaults to '<f4' (little-endian 32-bit float).

        Returns:
            VectorsDataset: A new instance containing the parsed vectors and their IDs.

        Raises:
            ValueError: If the number of values read doesn't match the expected size
                (number_of_vectors * dimension).
            IOError: If there are issues reading the file.
            TypeError: If the file content doesn't match the expected data types.

        Example:
            >>> dataset = VectorsDataset.__parse(
            ...     'vectors.bin',
            ...     dimension=128,
            ...     number_of_vectors=1000,
            ...     id_dtype='>i8',
            ...     vector_dtype='>f4'
            ... )

        Notes:
            - The binary file should contain vectors in a contiguous block
            - Data is expected to be in little-endian format ('<') for Java compatibility
            - Supported vector types:
                * '<f4': 32-bit float (Java float)
                * '<f8': 64-bit float (Java double)
            - Supported ID types:
                * '<i4': 32-bit integer (Java int)
                * '<i8': 64-bit integer (Java long)

        Memory Usage:
            The method will allocate memory for:
            - Vector array: number_of_vectors * dimension * sizeof(vector_dtype)
            - ID array: number_of_vectors * sizeof(id_dtype)
        """


        with open(vector_file, 'rb') as f:
            vectors = np.fromfile(f, dtype=vector_dtype,
                                  count=number_of_vectors * dimension)

            if len(vectors) != number_of_vectors * dimension:
                raise ValueError(
                    f"Expected {number_of_vectors * dimension} values, "
                    f"but got {len(vectors)}"
                )

                # Reshape the vectors array
            vectors = vectors.reshape(number_of_vectors, dimension)
            # TODO: Take these ids from S3.
            ids = np.array(range(number_of_vectors), dtype=np.int32)
            return VectorsDataset(vectors=vectors, dimensions=dimension, ids=ids)
